"""
AIè§£æã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆGroq + GPTå¯¾å¿œï¼‰
ãƒ¬ã‚·ãƒ”ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹é€ åŒ–ã¨ç¿»è¨³ã‚’æ‹…å½“
"""
import os
import json
from typing import Optional, Dict
from openai import OpenAI
from groq import Groq
from dotenv import load_dotenv

load_dotenv()

class GroqRecipeParser:
    def __init__(self, ai_provider="groq"):
        """
        AIè§£æã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
        
        Args:
            ai_provider: "groq" ã¾ãŸã¯ "gpt" ã‚’æŒ‡å®š
        """
        self.ai_provider = ai_provider
        
        if ai_provider == "groq":
            api_key = os.getenv("GROQ_API_KEY")
            if not api_key:
                raise ValueError("GROQ_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            
            self.client = Groq(api_key=api_key)
            self.model = "llama-3.1-8b-instant"  # Groqã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«
            print(f"ğŸ¤– Groq AI ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼ˆãƒ¢ãƒ‡ãƒ«: {self.model}ï¼‰")
            
        elif ai_provider == "gpt":
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            
            self.client = OpenAI(api_key=api_key)
            self.model = "gpt-4o-mini"  # GPT-4o-miniï¼ˆã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒè‰¯ã„ï¼‰
            print(f"ğŸ¤– GPT AI ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼ˆãƒ¢ãƒ‡ãƒ«: {self.model}ï¼‰")
            
        else:
            raise ValueError("ai_providerã¯ 'groq' ã¾ãŸã¯ 'gpt' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
    
    def parse_recipe_text(self, ocr_text: str) -> Optional[Dict]:
        """
        OCRã§æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¬ã‚·ãƒ”æƒ…å ±ã‚’æ§‹é€ åŒ–
        
        Args:
            ocr_text: OCRã§æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ¬ã‚·ãƒ”ãƒ‡ãƒ¼ã‚¿ï¼ˆè¾æ›¸å½¢å¼ï¼‰
            {
                "recipe_name": "æ–™ç†å",
                "servings": 2,
                "ingredients": [
                    {"name": "ç‰ã­ã", "quantity": 1.0, "unit": "å€‹"},
                    {"name": "è±šè‚‰", "quantity": 200.0, "unit": "g"}
                ]
            }
        """
        try:
            if self.ai_provider == "groq":
                return self._parse_with_groq(ocr_text)
            elif self.ai_provider == "gpt":
                return self._parse_with_gpt(ocr_text)
        except Exception as e:
            print(f"âŒ {self.ai_provider.upper()}è§£æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _parse_with_groq(self, ocr_text: str) -> Optional[Dict]:
        """Groqã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚·ãƒ”ã‚’è§£æ"""
        prompt = f"""ä»¥ä¸‹ã®OCRãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¬ã‚·ãƒ”æƒ…å ±ã‚’æŠ½å‡ºã—ã€å³å¯†ã«JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›å½¢å¼ã®å³å®ˆ:
{{"recipe_name": "æ–™ç†å", "servings": 2, "ingredients": [{{"name": "ææ–™å", "quantity": æ•°å€¤, "unit": "å˜ä½", "capacity": 1, "capacity_unit": "å€‹"}}]}}

## å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æŠ½å‡ºãƒ«ãƒ¼ãƒ«:
1.  **recipe_name**: ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‹ã‚‰ãƒ¬ã‚·ãƒ”ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç°¡æ½”ã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ææ–™ãƒªã‚¹ãƒˆã‚’é€£çµã—ãªã„ã§ãã ã•ã„ã€‚ã‚‚ã—ãƒ¬ã‚·ãƒ”åãŒæ˜ç¢ºã§ãªã„å ´åˆã¯ã€Œä¸æ˜ãªãƒ¬ã‚·ãƒ”ã€ã¨ã—ã¦ãã ã•ã„ã€‚
2.  **servings**: ãƒ¬ã‚·ãƒ”ã®äººæ•°ã‚’æ•°å€¤ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¸æ˜ãªå ´åˆã¯1ã¨ã—ã¦ãã ã•ã„ã€‚
3.  **ingredients**: å„ææ–™ã«ã¤ã„ã¦ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    *   **name**: ææ–™åã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    *   **quantity**: åˆ†é‡ã‚’æ•°å€¤ï¼ˆæ•´æ•°ã¾ãŸã¯å°æ•°ï¼‰ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ã€Œ1/4ã€ã®ã‚ˆã†ãªè¡¨è¨˜ã¯å°æ•°ï¼ˆä¾‹: 0.25ï¼‰ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚ã€Œé©é‡ã€ã®å ´åˆã¯0ã¨ã—ã¦ãã ã•ã„ã€‚**ã€Œå¤§ã•ã˜ã€ã€Œå°ã•ã˜ã€ã¯æ•°å€¤ã«å¤‰æ›ã›ãšã€å˜ä½ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚**
    *   **unit**: åˆ†é‡ã®å˜ä½ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¾‹: cc, g, æœ¬, å€‹, æš, å¤§ã•ã˜, å°ã•ã˜ã€‚**quantityãŒ0ã§ãªã„å ´åˆã€unitã¯ç©ºã«ã—ãªã„ã§ãã ã•ã„ã€‚**ã‚‚ã—å˜ä½ãŒä¸æ˜ãªå ´åˆã¯ã€Œå€‹ã€ã¨ã—ã¦ãã ã•ã„ã€‚
    *   **capacity**: å„ææ–™ã®åŸºæº–ã¨ãªã‚‹å®¹é‡ã‚’æ•°å€¤ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¸æ˜ãªå ´åˆã¯1ã¨ã—ã¦ãã ã•ã„ã€‚
    *   **capacity_unit**: capacityã®å˜ä½ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¸æ˜ãªå ´åˆã¯ã€Œå€‹ã€ã¨ã—ã¦ãã ã•ã„ã€‚**ã€Œå°ã€ã®ã‚ˆã†ãªå˜ä½ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚**

## é‡è¦ãªæ³¨æ„äº‹é …:
- **å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚**
- **ææ–™åã¨åˆ†é‡ãŒåˆ¥ã€…ã®è¡Œã«åˆ†ã‹ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€é©åˆ‡ã«çµåˆã—ã¦ãã ã•ã„ã€‚**
- **å‡ºåŠ›ã¯JSONã®ã¿ã¨ã—ã€ä½™åˆ†ãªèª¬æ˜æ–‡ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚**

ãƒ†ã‚­ã‚¹ãƒˆï¼š
{ocr_text}

JSONï¼š"""
        
        chat_completion = self.client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯JSONå‡ºåŠ›ã®å°‚é–€å®¶ã§ã™ã€‚å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¾ã™ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            model=self.model,
            temperature=0.1,
            max_tokens=1500
        )
        
        response_text = chat_completion.choices[0].message.content.strip()
        print(f"ğŸ” Groqç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response_text}")
        
        return self._extract_json_from_response(response_text)
    
    def _parse_with_gpt(self, ocr_text: str) -> Optional[Dict]:
        """GPTã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚·ãƒ”ã‚’è§£æ"""
        prompt = f"""ä»¥ä¸‹ã®OCRãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¬ã‚·ãƒ”æƒ…å ±ã‚’æŠ½å‡ºã—ã€å³å¯†ã«JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›å½¢å¼ã®å³å®ˆ:
{{"recipe_name": "æ–™ç†å", "servings": 2, "ingredients": [{{"name": "ææ–™å", "quantity": æ•°å€¤, "unit": "å˜ä½", "capacity": 1, "capacity_unit": "å€‹"}}]}}

## å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æŠ½å‡ºãƒ«ãƒ¼ãƒ«:
1.  **recipe_name**: ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‹ã‚‰ãƒ¬ã‚·ãƒ”ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç°¡æ½”ã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ææ–™ãƒªã‚¹ãƒˆã‚’é€£çµã—ãªã„ã§ãã ã•ã„ã€‚ã‚‚ã—ãƒ¬ã‚·ãƒ”åãŒæ˜ç¢ºã§ãªã„å ´åˆã¯ã€Œä¸æ˜ãªãƒ¬ã‚·ãƒ”ã€ã¨ã—ã¦ãã ã•ã„ã€‚
2.  **servings**: ãƒ¬ã‚·ãƒ”ã®äººæ•°ã‚’æ•°å€¤ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¸æ˜ãªå ´åˆã¯1ã¨ã—ã¦ãã ã•ã„ã€‚
3.  **ingredients**: å„ææ–™ã«ã¤ã„ã¦ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    *   **name**: ææ–™åã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    *   **quantity**: åˆ†é‡ã‚’æ•°å€¤ï¼ˆæ•´æ•°ã¾ãŸã¯å°æ•°ï¼‰ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ã€Œ1/4ã€ã®ã‚ˆã†ãªè¡¨è¨˜ã¯å°æ•°ï¼ˆä¾‹: 0.25ï¼‰ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚ã€Œé©é‡ã€ã®å ´åˆã¯0ã¨ã—ã¦ãã ã•ã„ã€‚**ã€Œå¤§ã•ã˜ã€ã€Œå°ã•ã˜ã€ã¯æ•°å€¤ã«å¤‰æ›ã›ãšã€å˜ä½ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚**
    *   **unit**: åˆ†é‡ã®å˜ä½ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¾‹: cc, g, æœ¬, å€‹, æš, å¤§ã•ã˜, å°ã•ã˜ã€‚**quantityãŒ0ã§ãªã„å ´åˆã€unitã¯ç©ºã«ã—ãªã„ã§ãã ã•ã„ã€‚**ã‚‚ã—å˜ä½ãŒä¸æ˜ãªå ´åˆã¯ã€Œå€‹ã€ã¨ã—ã¦ãã ã•ã„ã€‚
    *   **capacity**: å„ææ–™ã®åŸºæº–ã¨ãªã‚‹å®¹é‡ã‚’æ•°å€¤ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¸æ˜ãªå ´åˆã¯1ã¨ã—ã¦ãã ã•ã„ã€‚
    *   **capacity_unit**: capacityã®å˜ä½ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚ä¸æ˜ãªå ´åˆã¯ã€Œå€‹ã€ã¨ã—ã¦ãã ã•ã„ã€‚**ã€Œå°ã€ã®ã‚ˆã†ãªå˜ä½ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚**

## é‡è¦ãªæ³¨æ„äº‹é …:
- **å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚**
- **ææ–™åã¨åˆ†é‡ãŒåˆ¥ã€…ã®è¡Œã«åˆ†ã‹ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€é©åˆ‡ã«çµåˆã—ã¦ãã ã•ã„ã€‚**
- **å‡ºåŠ›ã¯JSONã®ã¿ã¨ã—ã€ä½™åˆ†ãªèª¬æ˜æ–‡ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚**

ãƒ†ã‚­ã‚¹ãƒˆï¼š
{ocr_text}

JSONï¼š"""
        
        chat_completion = self.client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯JSONå‡ºåŠ›ã®å°‚é–€å®¶ã§ã™ã€‚å¿…ãšæœ‰åŠ¹ãªJSONå½¢å¼ã§å‡ºåŠ›ã—ã¾ã™ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            model=self.model,
            temperature=0.1,
            max_tokens=1500
        )
        
        response_text = chat_completion.choices[0].message.content.strip()
        print(f"ğŸ” GPTç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response_text}")
        
        return self._extract_json_from_response(response_text)
    
    def _extract_json_from_response(self, response_text: str) -> Optional[Dict]:
        """AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONã‚’æŠ½å‡º"""
        try:
            # JSONã®æŠ½å‡ºï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§å›²ã¾ã‚Œã¦ã„ã‚‹å ´åˆã«å¯¾å¿œï¼‰
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
                print(f"ğŸ” JSONãƒ–ãƒ­ãƒƒã‚¯æŠ½å‡ºå¾Œ: {response_text}")
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()
                print(f"ğŸ” ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æŠ½å‡ºå¾Œ: {response_text}")
            
            # JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é–‹å§‹ã¨çµ‚äº†ã‚’æ¢ã™
            if "{" in response_text and "}" in response_text:
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                response_text = response_text[start:end]
                print(f"ğŸ” JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŠ½å‡ºå¾Œ: {response_text}")
            
            # JSONã‚’ãƒ‘ãƒ¼ã‚¹
            recipe_data = json.loads(response_text)
            
            print(f"âœ… JSONè§£ææˆåŠŸ: {recipe_data}")
            
            # ä¸è¶³ã—ã¦ã„ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è‡ªå‹•è£œå®Œ
            for ingredient in recipe_data.get('ingredients', []):
                if 'capacity' not in ingredient:
                    ingredient['capacity'] = 1
                if 'capacity_unit' not in ingredient:
                    ingredient['capacity_unit'] = 'å€‹'
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            if not self._validate_recipe_data(recipe_data):
                print(f"âŒ ãƒ¬ã‚·ãƒ”ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                print(f"ãƒ‡ãƒ¼ã‚¿å†…å®¹: {json.dumps(recipe_data, ensure_ascii=False, indent=2)}")
                return None
            
            print(f"âœ… ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸ")
            return recipe_data
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            print(f"AIãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response_text}")
            return None
        except Exception as e:
            print(f"âŒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _validate_recipe_data(self, data: Dict) -> bool:
        """ãƒ¬ã‚·ãƒ”ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not isinstance(data, dict):
            return False
        
        if 'recipe_name' not in data or 'servings' not in data or 'ingredients' not in data:
            return False
        
        if not isinstance(data['servings'], int) or data['servings'] <= 0:
            return False
        
        if not isinstance(data['ingredients'], list):
            return False
        
        for ingredient in data['ingredients']:
            if not isinstance(ingredient, dict):
                return False
            if 'name' not in ingredient or 'quantity' not in ingredient or 'unit' not in ingredient:
                return False
        
        return True
    
    def translate_text(self, text: str, target_language: str = "ja") -> Optional[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šè¨€èªã«ç¿»è¨³"""
        try:
            if self.ai_provider == "groq":
                return self._translate_with_groq(text, target_language)
            elif self.ai_provider == "gpt":
                return self._translate_with_gpt(text, target_language)
        except Exception as e:
            print(f"âŒ {self.ai_provider.upper()}ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _translate_with_groq(self, text: str, target_language: str) -> Optional[str]:
        """Groqã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³"""
        prompt = f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’{target_language}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š\n\n{text}"
        
        response = self.client.chat.completions.create(
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ç¿»è¨³ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            model=self.model,
            temperature=0.1,
            max_tokens=1000
        )
        
        return response.choices[0].message.content.strip()
    
    def _translate_with_gpt(self, text: str, target_language: str) -> Optional[str]:
        """GPTã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³"""
        prompt = f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’{target_language}ã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š\n\n{text}"
        
        response = self.client.chat.completions.create(
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ç¿»è¨³ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            model=self.model,
            temperature=0.1,
            max_tokens=1000
        )
        
        return response.choices[0].message.content.strip()